## 基于飞桨实现乒乓球时序动作定位大赛 ：B榜第7名方案

## 赛题介绍
在众多大规模视频分析情景中，从冗长未经修剪的视频中定位并识别短时间内发生的人体动作成为一个备受关注的课题。当前针对人体动作检测的解决方案在大规模视频集上难以奏效，高效地处理大规模视频数据仍然是计算机视觉领域一个充满挑战的任务。其核心问题可以分为两部分，一是动作识别算法的复杂度仍旧较高，二是缺少能够产生更少视频提案数量的方法（更加关注短时动作本身的提案）。

这里所指的视频动作提案是指一些包含特定动作的候选视频片段。为了能够适应大规模视频分析任务，时序动作提案应该尽可能满足下面两个需求： （1）更高的处理效率，例如可以设计出使时序视频片段编码和打分更高效的机制； （2）更强的判别性能，例如可以准确定位动作发生的时间区间。

本次比赛旨在激发更多的开发者和研究人员关注并参与有关视频动作定位的研究，创建性能更出色的动作定位模型。

## 数据集介绍
本次比赛的数据集包含了19-21赛季兵乓球国际比赛（世界杯、世锦赛、亚锦赛，奥运会）和国内比赛（全运会，乒超联赛）中标准单机位高清转播画面的特征信息，共包含912条视频特征文件，每个视频时长在0～6分钟不等，特征维度为2048，以pkl格式保存。我们对特征数据中面朝镜头的运动员的回合内挥拍动作进行了标注，单个动作时常在0～2秒不等，训练数据为729条标注视频，A测数据为91条视频，B测数据为92条视频，训练数据标签以json格式给出。

## 数据集预处理
设定滑动窗口（window）大小为4，当滑动窗口每次划过数组时，计算当前滑动窗口中元素的和，得到结果res
本方案采用PaddleVideo中的BMN模型。BMN模型是百度自研，2019年ActivityNet夺冠方案，为视频动作定位问题中proposal的生成提供高效的解决方案，在PaddlePaddle上首次开源。此模型引入边界匹配(Boundary-Matching, BM)机制来评估proposal的置信度，按照proposal开始边界的位置及其长度将所有可能存在的proposal组合成一个二维的BM置信度图，图中每个点的数值代表其所对应的proposal的置信度分数。网络由三个模块组成，基础模块作为主干网络处理输入的特征序列，TEM模块预测每一个时序位置属于动作开始、动作结束的概率，PEM模块生成BM置信度图。

本赛题中的数据包含912条ppTSM抽取的视频特征，特征保存为pkl格式，文件名对应视频名称，读取pkl之后以(num_of_frames, 2048)向量形式代表单个视频特征。其中num_of_frames是不固定的，同时数量也比较大，所以pkl的文件并不能直接用于训练。同时由于乒乓球每个动作时间非常短，为了可以让模型更好的识别动作，所以这里将数据进行分割。

### 思路介绍

* 本赛题数据分割，参考[BMN_tabletennis](https://github.com/PaddlePaddle/PaddleVideo/blob/develop/applications/TableTennis/get_instance_for_bmn.py)的数据分割方式，使用宽4s的滑窗,把每一个视频里的动作片段提取出来,分割为4X25=100帧的数据。
* 本项目基于[BMN]参考项目(https://aistudio.baidu.com/aistudio/projectdetail/3434130?channelType=0&channel=0)

### 具体方案分享

使用飞桨开源深度学习平台非常方面，给人工智能进学校提供了很多便利，不但有丰富的项目案例，教学视频，还有针对性的帮扶以及免费优质的运算资源。基本上解决了让深度学习技术的创新与应用更简单的历史难题。
本比赛参考了大佬分享的项目，在参数方面做了些调整，没有得到很大的提升，对滑窗选择了4，因为本人也是乒乓球运动员，明白每个动作时间非常断甚至不到1秒，因此没有选择滑窗8，而选择了只有一半的滑窗4。测试了epoch较好的值。

BMN模型结构

![image](https://user-images.githubusercontent.com/62683546/156315582-dc4088df-47f0-4a66-b4f3-1dea80deedff.png)


